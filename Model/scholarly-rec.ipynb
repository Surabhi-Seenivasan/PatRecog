{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b32acf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd25bcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles=pd.read_csv('arxiv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e23a7b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Improved training of neural trans-dimensional ...</td>\n",
       "      <td>A new whole-sentence language model - neural t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The price of debiasing automatic metrics in na...</td>\n",
       "      <td>For evaluating generation systems, automatic m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NMT-Keras: a Very Flexible Toolkit with a Focu...</td>\n",
       "      <td>We present NMT-Keras, a flexible toolkit for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natural Language Processing for Information Ex...</td>\n",
       "      <td>With rise of digital age, there is an explosio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automatic Short Answer Grading and Feedback Us...</td>\n",
       "      <td>Automatic grading is not a new approach but th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  Improved training of neural trans-dimensional ...   \n",
       "1  The price of debiasing automatic metrics in na...   \n",
       "2  NMT-Keras: a Very Flexible Toolkit with a Focu...   \n",
       "3  Natural Language Processing for Information Ex...   \n",
       "4  Automatic Short Answer Grading and Feedback Us...   \n",
       "\n",
       "                                            abstract  \n",
       "0  A new whole-sentence language model - neural t...  \n",
       "1  For evaluating generation systems, automatic m...  \n",
       "2  We present NMT-Keras, a flexible toolkit for t...  \n",
       "3  With rise of digital age, there is an explosio...  \n",
       "4  Automatic grading is not a new approach but th...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11a5e06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article     0\n",
       "abstract    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a581b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25352, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56b427df",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['abstract']=articles['abstract'].apply(lambda x:x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49b86e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Improved training of neural trans-dimensional ...</td>\n",
       "      <td>[A, new, whole-sentence, language, model, -, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The price of debiasing automatic metrics in na...</td>\n",
       "      <td>[For, evaluating, generation, systems,, automa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NMT-Keras: a Very Flexible Toolkit with a Focu...</td>\n",
       "      <td>[We, present, NMT-Keras,, a, flexible, toolkit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natural Language Processing for Information Ex...</td>\n",
       "      <td>[With, rise, of, digital, age,, there, is, an,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automatic Short Answer Grading and Feedback Us...</td>\n",
       "      <td>[Automatic, grading, is, not, a, new, approach...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  Improved training of neural trans-dimensional ...   \n",
       "1  The price of debiasing automatic metrics in na...   \n",
       "2  NMT-Keras: a Very Flexible Toolkit with a Focu...   \n",
       "3  Natural Language Processing for Information Ex...   \n",
       "4  Automatic Short Answer Grading and Feedback Us...   \n",
       "\n",
       "                                            abstract  \n",
       "0  [A, new, whole-sentence, language, model, -, n...  \n",
       "1  [For, evaluating, generation, systems,, automa...  \n",
       "2  [We, present, NMT-Keras,, a, flexible, toolkit...  \n",
       "3  [With, rise, of, digital, age,, there, is, an,...  \n",
       "4  [Automatic, grading, is, not, a, new, approach...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55ca750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['abstract']=articles['abstract'].apply(lambda x:[i.replace(\" \", \"\") for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edcdee3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Improved training of neural trans-dimensional ...</td>\n",
       "      <td>[A, new, whole-sentence, language, model, -, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The price of debiasing automatic metrics in na...</td>\n",
       "      <td>[For, evaluating, generation, systems,, automa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NMT-Keras: a Very Flexible Toolkit with a Focu...</td>\n",
       "      <td>[We, present, NMT-Keras,, a, flexible, toolkit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natural Language Processing for Information Ex...</td>\n",
       "      <td>[With, rise, of, digital, age,, there, is, an,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automatic Short Answer Grading and Feedback Us...</td>\n",
       "      <td>[Automatic, grading, is, not, a, new, approach...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  Improved training of neural trans-dimensional ...   \n",
       "1  The price of debiasing automatic metrics in na...   \n",
       "2  NMT-Keras: a Very Flexible Toolkit with a Focu...   \n",
       "3  Natural Language Processing for Information Ex...   \n",
       "4  Automatic Short Answer Grading and Feedback Us...   \n",
       "\n",
       "                                            abstract  \n",
       "0  [A, new, whole-sentence, language, model, -, n...  \n",
       "1  [For, evaluating, generation, systems,, automa...  \n",
       "2  [We, present, NMT-Keras,, a, flexible, toolkit...  \n",
       "3  [With, rise, of, digital, age,, there, is, an,...  \n",
       "4  [Automatic, grading, is, not, a, new, approach...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0bed4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['tags']= articles['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08f58bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Improved training of neural trans-dimensional ...</td>\n",
       "      <td>[A, new, whole-sentence, language, model, -, n...</td>\n",
       "      <td>[A, new, whole-sentence, language, model, -, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The price of debiasing automatic metrics in na...</td>\n",
       "      <td>[For, evaluating, generation, systems,, automa...</td>\n",
       "      <td>[For, evaluating, generation, systems,, automa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NMT-Keras: a Very Flexible Toolkit with a Focu...</td>\n",
       "      <td>[We, present, NMT-Keras,, a, flexible, toolkit...</td>\n",
       "      <td>[We, present, NMT-Keras,, a, flexible, toolkit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natural Language Processing for Information Ex...</td>\n",
       "      <td>[With, rise, of, digital, age,, there, is, an,...</td>\n",
       "      <td>[With, rise, of, digital, age,, there, is, an,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automatic Short Answer Grading and Feedback Us...</td>\n",
       "      <td>[Automatic, grading, is, not, a, new, approach...</td>\n",
       "      <td>[Automatic, grading, is, not, a, new, approach...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  Improved training of neural trans-dimensional ...   \n",
       "1  The price of debiasing automatic metrics in na...   \n",
       "2  NMT-Keras: a Very Flexible Toolkit with a Focu...   \n",
       "3  Natural Language Processing for Information Ex...   \n",
       "4  Automatic Short Answer Grading and Feedback Us...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  [A, new, whole-sentence, language, model, -, n...   \n",
       "1  [For, evaluating, generation, systems,, automa...   \n",
       "2  [We, present, NMT-Keras,, a, flexible, toolkit...   \n",
       "3  [With, rise, of, digital, age,, there, is, an,...   \n",
       "4  [Automatic, grading, is, not, a, new, approach...   \n",
       "\n",
       "                                                tags  \n",
       "0  [A, new, whole-sentence, language, model, -, n...  \n",
       "1  [For, evaluating, generation, systems,, automa...  \n",
       "2  [We, present, NMT-Keras,, a, flexible, toolkit...  \n",
       "3  [With, rise, of, digital, age,, there, is, an,...  \n",
       "4  [Automatic, grading, is, not, a, new, approach...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cad064ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ad463b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9e7f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    y = []\n",
    "    \n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))\n",
    "        \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0e651a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=articles[['article','tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be1ac24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Surabhi\\AppData\\Local\\Temp\\ipykernel_16320\\684433085.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags']=new_df['tags'].apply(lambda x: \" \".join(x))\n"
     ]
    }
   ],
   "source": [
    "new_df['tags']=new_df['tags'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "464cd492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Surabhi\\AppData\\Local\\Temp\\ipykernel_16320\\3514595201.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags']=new_df['tags'].apply(stem)\n"
     ]
    }
   ],
   "source": [
    "new_df['tags']=new_df['tags'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b945e317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Improved training of neural trans-dimensional ...</td>\n",
       "      <td>a new whole-sent languag model - neural trans-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The price of debiasing automatic metrics in na...</td>\n",
       "      <td>for evalu gener systems, automat metric such a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NMT-Keras: a Very Flexible Toolkit with a Focu...</td>\n",
       "      <td>we present nmt-keras, a flexibl toolkit for tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natural Language Processing for Information Ex...</td>\n",
       "      <td>with rise of digit age, there is an explos of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automatic Short Answer Grading and Feedback Us...</td>\n",
       "      <td>automat grade is not a new approach but the ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  Improved training of neural trans-dimensional ...   \n",
       "1  The price of debiasing automatic metrics in na...   \n",
       "2  NMT-Keras: a Very Flexible Toolkit with a Focu...   \n",
       "3  Natural Language Processing for Information Ex...   \n",
       "4  Automatic Short Answer Grading and Feedback Us...   \n",
       "\n",
       "                                                tags  \n",
       "0  a new whole-sent languag model - neural trans-...  \n",
       "1  for evalu gener systems, automat metric such a...  \n",
       "2  we present nmt-keras, a flexibl toolkit for tr...  \n",
       "3  with rise of digit age, there is an explos of ...  \n",
       "4  automat grade is not a new approach but the ne...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d3f3f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Surabhi\\AppData\\Local\\Temp\\ipykernel_16320\\4224080999.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags']=new_df['tags'].apply(lambda x:x.lower())\n"
     ]
    }
   ],
   "source": [
    "new_df['tags']=new_df['tags'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af759f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Improved training of neural trans-dimensional ...</td>\n",
       "      <td>a new whole-sent languag model - neural trans-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The price of debiasing automatic metrics in na...</td>\n",
       "      <td>for evalu gener systems, automat metric such a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NMT-Keras: a Very Flexible Toolkit with a Focu...</td>\n",
       "      <td>we present nmt-keras, a flexibl toolkit for tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natural Language Processing for Information Ex...</td>\n",
       "      <td>with rise of digit age, there is an explos of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automatic Short Answer Grading and Feedback Us...</td>\n",
       "      <td>automat grade is not a new approach but the ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  Improved training of neural trans-dimensional ...   \n",
       "1  The price of debiasing automatic metrics in na...   \n",
       "2  NMT-Keras: a Very Flexible Toolkit with a Focu...   \n",
       "3  Natural Language Processing for Information Ex...   \n",
       "4  Automatic Short Answer Grading and Feedback Us...   \n",
       "\n",
       "                                                tags  \n",
       "0  a new whole-sent languag model - neural trans-...  \n",
       "1  for evalu gener systems, automat metric such a...  \n",
       "2  we present nmt-keras, a flexibl toolkit for tr...  \n",
       "3  with rise of digit age, there is an explos of ...  \n",
       "4  automat grade is not a new approach but the ne...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32501122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thi paper present our system for \"trac 2018 share task on aggress identification\". our best system for the english dataset use a combin of lexic and semant features. however, for hindi data use onli lexic featur gave us the best results. we obtain weight f1- measur of 0.5921 for the english facebook task (rank 12th), 0.5663 for the english social media task (rank 6th), 0.6292 for the hindi facebook task (rank 1st), and 0.4853 for the hindi social media task (rank 2nd).'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[\"tags\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "537935a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv= CountVectorizer(max_features=5000, stop_words='english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "923e7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = cv.fit_transform(new_df['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "842104f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1c03363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Surabhi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '01',\n",
       " '02',\n",
       " '03',\n",
       " '05',\n",
       " '06',\n",
       " '09',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '100k',\n",
       " '103',\n",
       " '10k',\n",
       " '11',\n",
       " '110',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '140',\n",
       " '15',\n",
       " '150',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '1d',\n",
       " '1m',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '2020',\n",
       " '2021',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '250',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '2d',\n",
       " '2nd',\n",
       " '2x',\n",
       " '30',\n",
       " '300',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '3d',\n",
       " '3rd',\n",
       " '3x',\n",
       " '40',\n",
       " '400',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '4th',\n",
       " '4x',\n",
       " '50',\n",
       " '500',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '5k',\n",
       " '5x',\n",
       " '60',\n",
       " '600',\n",
       " '61',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '90',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " 'aa',\n",
       " 'abbrevi',\n",
       " 'abbreviations',\n",
       " 'abduct',\n",
       " 'abil',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abl',\n",
       " 'ablat',\n",
       " 'abnorm',\n",
       " 'abov',\n",
       " 'absa',\n",
       " 'absenc',\n",
       " 'absent',\n",
       " 'absolut',\n",
       " 'absolute',\n",
       " 'abstract',\n",
       " 'abstraction',\n",
       " 'abstracts',\n",
       " 'abund',\n",
       " 'abus',\n",
       " 'abx',\n",
       " 'ac',\n",
       " 'academ',\n",
       " 'academia',\n",
       " 'acceler',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accid',\n",
       " 'accommod',\n",
       " 'accompani',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'accumul',\n",
       " 'accur',\n",
       " 'accuraci',\n",
       " 'accuracies',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'ace',\n",
       " 'achiev',\n",
       " 'achieved',\n",
       " 'acknowledg',\n",
       " 'acl',\n",
       " 'acoust',\n",
       " 'acoustic',\n",
       " 'acquir',\n",
       " 'acquisit',\n",
       " 'acquisition',\n",
       " 'acronym',\n",
       " 'act',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activ',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'ad',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'add',\n",
       " 'addit',\n",
       " 'addition',\n",
       " 'additionally',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'adequ',\n",
       " 'adequaci',\n",
       " 'adher',\n",
       " 'adjac',\n",
       " 'adject',\n",
       " 'adjectives',\n",
       " 'adjust',\n",
       " 'administr',\n",
       " 'admiss',\n",
       " 'admit',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adr',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'advanc',\n",
       " 'advance',\n",
       " 'advantag',\n",
       " 'advantages',\n",
       " 'advent',\n",
       " 'advers',\n",
       " 'adversari',\n",
       " 'advertis',\n",
       " 'advic',\n",
       " 'advoc',\n",
       " 'ae',\n",
       " 'affect',\n",
       " 'affin',\n",
       " 'afford',\n",
       " 'aforement',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'ag',\n",
       " 'age',\n",
       " 'agenc',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'agglutin',\n",
       " 'aggreg',\n",
       " 'aggress',\n",
       " 'agnost',\n",
       " 'agnostic',\n",
       " 'ago',\n",
       " 'agre',\n",
       " 'agreement',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'aishell',\n",
       " 'al',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alert',\n",
       " 'alexa',\n",
       " 'algebra',\n",
       " 'algorithm',\n",
       " 'algorithms',\n",
       " 'align',\n",
       " 'alignment',\n",
       " 'alignments',\n",
       " 'allevi',\n",
       " 'alloc',\n",
       " 'allocation',\n",
       " 'allow',\n",
       " 'alon',\n",
       " 'alongsid',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'alreadi',\n",
       " 'alter',\n",
       " 'altern',\n",
       " 'alternative',\n",
       " 'alternatives',\n",
       " 'alway',\n",
       " 'alzheimer',\n",
       " 'amazon',\n",
       " 'ambigu',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'amen',\n",
       " 'american',\n",
       " 'ami',\n",
       " 'ampl',\n",
       " 'amplifi',\n",
       " 'amr',\n",
       " 'analog',\n",
       " 'analogy',\n",
       " 'analys',\n",
       " 'analyses',\n",
       " 'analysi',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'analyt',\n",
       " 'analytics',\n",
       " 'analyz',\n",
       " 'analyzed',\n",
       " 'anaphor',\n",
       " 'anaphora',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'anger',\n",
       " 'ani',\n",
       " 'anim',\n",
       " 'ann',\n",
       " 'annot',\n",
       " 'annotated',\n",
       " 'annotation',\n",
       " 'annotations',\n",
       " 'annotators',\n",
       " 'anomali',\n",
       " 'anonym',\n",
       " 'anoth',\n",
       " 'answ',\n",
       " 'answer',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'anteced',\n",
       " 'anti',\n",
       " 'anticip',\n",
       " 'antonym',\n",
       " 'ap',\n",
       " 'apach',\n",
       " 'apart',\n",
       " 'ape',\n",
       " 'api',\n",
       " 'apis',\n",
       " 'app',\n",
       " 'appar',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appl',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'applicable',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'applied',\n",
       " 'apprais',\n",
       " 'approach',\n",
       " 'approaches',\n",
       " 'appropri',\n",
       " 'approxim',\n",
       " 'approximation',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'arabic',\n",
       " 'arabizi',\n",
       " 'arbitrari',\n",
       " 'arbitrarili',\n",
       " 'arc',\n",
       " 'architectur',\n",
       " 'architecture',\n",
       " 'architectures',\n",
       " 'archiv',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'argu',\n",
       " 'arguabl',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'ari',\n",
       " 'aris',\n",
       " 'arithmet',\n",
       " 'arm',\n",
       " 'arous',\n",
       " 'arrang',\n",
       " 'array',\n",
       " 'arriv',\n",
       " 'art',\n",
       " 'articl',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'articul',\n",
       " 'articulatori',\n",
       " 'artifact',\n",
       " 'artifacts',\n",
       " 'artifici',\n",
       " 'artist',\n",
       " 'arxiv',\n",
       " 'asian',\n",
       " 'ask',\n",
       " 'asp',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'asr',\n",
       " 'assembl',\n",
       " 'assert',\n",
       " 'assess',\n",
       " 'assessment',\n",
       " 'assessments',\n",
       " 'assign',\n",
       " 'assist',\n",
       " 'assistant',\n",
       " 'assistants',\n",
       " 'associ',\n",
       " 'associations',\n",
       " 'assum',\n",
       " 'assumpt',\n",
       " 'assumption',\n",
       " 'assumptions',\n",
       " 'ast',\n",
       " 'asymmetr',\n",
       " 'asymmetri',\n",
       " 'asymptot',\n",
       " 'asynchron',\n",
       " 'ate',\n",
       " 'ati',\n",
       " 'atom',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attacks',\n",
       " 'attain',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'attention',\n",
       " 'attentions',\n",
       " 'attenu',\n",
       " 'attest',\n",
       " 'attitud',\n",
       " 'attract',\n",
       " 'attribut',\n",
       " 'attribute',\n",
       " 'attributes',\n",
       " 'attribution',\n",
       " 'auc',\n",
       " 'audienc',\n",
       " 'audience',\n",
       " 'audio',\n",
       " 'audiovisu',\n",
       " 'audit',\n",
       " 'auditori',\n",
       " 'aug',\n",
       " 'augment',\n",
       " 'augmentation',\n",
       " 'authent',\n",
       " 'author',\n",
       " 'authors',\n",
       " 'authorship',\n",
       " 'auto',\n",
       " 'autoencod',\n",
       " 'autoencoder',\n",
       " 'autoencoders',\n",
       " 'autom',\n",
       " 'automat',\n",
       " 'automata',\n",
       " 'automatically',\n",
       " 'automation',\n",
       " 'automaton',\n",
       " 'autonom',\n",
       " 'autoregress',\n",
       " 'auxiliari',\n",
       " 'av',\n",
       " 'avail',\n",
       " 'availability',\n",
       " 'available',\n",
       " 'avenu',\n",
       " 'averag',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'avsd',\n",
       " 'awar',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'babi',\n",
       " 'backbon',\n",
       " 'background',\n",
       " 'backpropag',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'balanc',\n",
       " 'band',\n",
       " 'bandit',\n",
       " 'bandwidth',\n",
       " 'bangla',\n",
       " 'bank',\n",
       " 'bare',\n",
       " 'barrier',\n",
       " 'bart',\n",
       " 'bas',\n",
       " 'base',\n",
       " 'based',\n",
       " 'baselin',\n",
       " 'baseline',\n",
       " 'baselines',\n",
       " 'bases',\n",
       " 'basi',\n",
       " 'basic',\n",
       " 'basis',\n",
       " 'batch',\n",
       " 'batteri',\n",
       " 'bay',\n",
       " 'bayes',\n",
       " 'bayesian',\n",
       " 'beam',\n",
       " 'beamform',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'becam',\n",
       " 'becaus',\n",
       " 'becom',\n",
       " 'befor',\n",
       " 'begin',\n",
       " 'behav',\n",
       " 'behavior',\n",
       " 'behaviors',\n",
       " 'behaviour',\n",
       " 'belief',\n",
       " 'beliefs',\n",
       " 'believ',\n",
       " 'belong',\n",
       " 'benchmark',\n",
       " 'benchmarks',\n",
       " 'benefici',\n",
       " 'beneficial',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'bengali',\n",
       " 'bert',\n",
       " 'besid',\n",
       " 'best',\n",
       " 'beta',\n",
       " 'better',\n",
       " 'bf',\n",
       " 'bi',\n",
       " 'bia',\n",
       " 'biaffin',\n",
       " 'bias',\n",
       " 'biases',\n",
       " 'bibl',\n",
       " 'bidaf',\n",
       " 'bidirect',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bigram',\n",
       " 'bilinear',\n",
       " 'bilingu',\n",
       " 'billion',\n",
       " 'bilstm',\n",
       " 'binari',\n",
       " 'bind',\n",
       " 'bio',\n",
       " 'bioasq',\n",
       " 'biobert',\n",
       " 'biolog',\n",
       " 'biomed',\n",
       " 'bioner',\n",
       " 'bionlp',\n",
       " 'birth',\n",
       " 'bit',\n",
       " 'bitext',\n",
       " 'bits',\n",
       " 'black',\n",
       " 'blank',\n",
       " 'blend',\n",
       " 'bleu',\n",
       " 'bli',\n",
       " 'blind',\n",
       " 'block',\n",
       " 'blocks',\n",
       " 'blog',\n",
       " 'blogs',\n",
       " 'blstm',\n",
       " 'bm25',\n",
       " 'bn',\n",
       " 'board',\n",
       " 'bodi',\n",
       " 'book',\n",
       " 'books',\n",
       " 'boolean',\n",
       " 'boost',\n",
       " 'bootstrap',\n",
       " 'borrow',\n",
       " 'bot',\n",
       " 'bots',\n",
       " 'bottleneck',\n",
       " 'bound',\n",
       " 'boundari',\n",
       " 'boundaries',\n",
       " 'boundary',\n",
       " 'bow',\n",
       " 'box',\n",
       " 'boxes',\n",
       " 'bpe',\n",
       " 'bracket',\n",
       " 'brain',\n",
       " 'branch',\n",
       " 'brand',\n",
       " 'brazilian',\n",
       " 'break',\n",
       " 'breakthrough',\n",
       " 'bridg',\n",
       " 'brief',\n",
       " 'briefli',\n",
       " 'bring',\n",
       " 'british',\n",
       " 'broad',\n",
       " 'broadcast',\n",
       " 'broader',\n",
       " 'broadli',\n",
       " 'broken',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brows',\n",
       " 'budget',\n",
       " 'build',\n",
       " 'building',\n",
       " 'built',\n",
       " 'bulgarian',\n",
       " 'burden',\n",
       " 'busi',\n",
       " 'business',\n",
       " 'buy',\n",
       " 'bypass',\n",
       " 'byte',\n",
       " 'ca',\n",
       " 'cach',\n",
       " 'cae',\n",
       " 'cal',\n",
       " 'calcul',\n",
       " 'calculation',\n",
       " 'calculu',\n",
       " 'calculus',\n",
       " 'calibr',\n",
       " 'calibration',\n",
       " 'callhom',\n",
       " 'campaign',\n",
       " 'campaigns',\n",
       " 'cancer',\n",
       " 'candid',\n",
       " 'candidate',\n",
       " 'candidates',\n",
       " 'canon',\n",
       " 'capabilities',\n",
       " 'capability',\n",
       " 'capabl',\n",
       " 'capac',\n",
       " 'capacity',\n",
       " 'capit',\n",
       " 'capsul',\n",
       " 'capt',\n",
       " 'caption',\n",
       " 'captioning',\n",
       " 'captions',\n",
       " 'captur',\n",
       " 'car',\n",
       " 'care',\n",
       " 'carlo',\n",
       " 'carri',\n",
       " 'cas',\n",
       " 'cascad',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'cast',\n",
       " 'cat',\n",
       " 'catalan',\n",
       " 'catalog',\n",
       " 'catastroph',\n",
       " 'catch',\n",
       " 'categor',\n",
       " 'categori',\n",
       " 'categories',\n",
       " 'categoris',\n",
       " 'categorization',\n",
       " 'category',\n",
       " 'cater',\n",
       " 'caus',\n",
       " 'causal',\n",
       " 'cause',\n",
       " 'cbow',\n",
       " 'cc',\n",
       " 'cca',\n",
       " 'ccg',\n",
       " 'cd',\n",
       " 'ce',\n",
       " 'celebr',\n",
       " 'cell',\n",
       " 'cent',\n",
       " 'center',\n",
       " 'centr',\n",
       " 'central',\n",
       " 'centroid',\n",
       " 'centuri',\n",
       " 'century',\n",
       " 'cepstral',\n",
       " 'cer',\n",
       " 'certain',\n",
       " 'cf',\n",
       " 'cfg',\n",
       " 'chain',\n",
       " 'chains',\n",
       " 'challeng',\n",
       " 'challenge',\n",
       " 'challenges',\n",
       " 'challenging',\n",
       " 'chanc',\n",
       " 'chang',\n",
       " 'change',\n",
       " 'changes',\n",
       " 'channel',\n",
       " 'channels',\n",
       " 'chapter',\n",
       " 'char',\n",
       " 'charact',\n",
       " 'character',\n",
       " 'characteris',\n",
       " 'characterist',\n",
       " 'characteristics',\n",
       " 'characters',\n",
       " 'charg',\n",
       " 'chart',\n",
       " 'chat',\n",
       " 'chatbot',\n",
       " 'chatbots',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'check',\n",
       " 'checker',\n",
       " 'checking',\n",
       " 'chemic',\n",
       " 'chess',\n",
       " 'chest',\n",
       " 'child',\n",
       " 'children',\n",
       " 'chime',\n",
       " 'china',\n",
       " 'chines',\n",
       " 'chinese',\n",
       " 'chit',\n",
       " 'choic',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'choos',\n",
       " 'chosen',\n",
       " 'chunk',\n",
       " 'chunking',\n",
       " 'ci',\n",
       " 'cider',\n",
       " 'circuit',\n",
       " 'circumst',\n",
       " 'circumv',\n",
       " 'citat',\n",
       " 'citations',\n",
       " 'cite',\n",
       " 'citi',\n",
       " 'citizen',\n",
       " 'cl',\n",
       " 'claim',\n",
       " 'claims',\n",
       " 'clarif',\n",
       " 'clarifi',\n",
       " 'class',\n",
       " 'classes',\n",
       " 'classic',\n",
       " 'classif',\n",
       " 'classifi',\n",
       " 'classification',\n",
       " 'classifier',\n",
       " 'classifiers',\n",
       " 'classroom',\n",
       " 'claus',\n",
       " 'clause',\n",
       " 'clauses',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearli',\n",
       " 'clef',\n",
       " 'clevr',\n",
       " 'click',\n",
       " 'clickbait',\n",
       " 'client',\n",
       " 'climat',\n",
       " 'clinic',\n",
       " 'clinician',\n",
       " 'clip',\n",
       " 'clir',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'cloud',\n",
       " 'cloze',\n",
       " 'cls',\n",
       " 'clue',\n",
       " 'clust',\n",
       " 'cluster',\n",
       " 'clustering',\n",
       " 'clusters',\n",
       " 'cm',\n",
       " 'cmu',\n",
       " 'cn',\n",
       " 'cnl',\n",
       " 'cnn',\n",
       " 'cnns',\n",
       " 'coars',\n",
       " 'coarse',\n",
       " 'coco',\n",
       " 'cod',\n",
       " 'code',\n",
       " 'codebook',\n",
       " 'codes',\n",
       " 'coding',\n",
       " 'coeffici',\n",
       " 'cognat',\n",
       " 'cognit',\n",
       " 'cognition',\n",
       " 'coher',\n",
       " 'coherence',\n",
       " 'coherent',\n",
       " 'cohes',\n",
       " 'cohort',\n",
       " 'cold',\n",
       " 'collabor',\n",
       " 'collaps',\n",
       " 'collapse',\n",
       " 'collect',\n",
       " 'collected',\n",
       " 'collection',\n",
       " 'collections',\n",
       " 'colloc',\n",
       " 'colloqui',\n",
       " 'color',\n",
       " 'colour',\n",
       " 'column',\n",
       " 'com',\n",
       " 'combat',\n",
       " 'combin',\n",
       " 'combination',\n",
       " 'combinations',\n",
       " 'combinatori',\n",
       " 'combined',\n",
       " 'come',\n",
       " 'command',\n",
       " 'commands',\n",
       " 'comment',\n",
       " 'commentari',\n",
       " 'comments',\n",
       " 'commerc',\n",
       " 'commerce',\n",
       " 'commerci',\n",
       " 'commit',\n",
       " 'common',\n",
       " 'commonli',\n",
       " 'commonly',\n",
       " 'commonsens',\n",
       " 'commonsense',\n",
       " 'commonsenseqa',\n",
       " 'commun',\n",
       " 'communication',\n",
       " 'communities',\n",
       " 'community',\n",
       " 'commut',\n",
       " 'compact',\n",
       " 'compani',\n",
       " 'companies',\n",
       " 'company',\n",
       " 'compar',\n",
       " 'compared',\n",
       " 'comparison',\n",
       " 'comparisons',\n",
       " 'compat',\n",
       " 'compel',\n",
       " 'compens',\n",
       " 'compet',\n",
       " 'competit',\n",
       " 'competition',\n",
       " 'competitions',\n",
       " 'competitor',\n",
       " 'compil',\n",
       " 'complaint',\n",
       " 'complement',\n",
       " 'complementari',\n",
       " 'complet',\n",
       " 'complete',\n",
       " 'completion',\n",
       " 'complex',\n",
       " 'complexity',\n",
       " 'compli',\n",
       " 'complic',\n",
       " 'compon',\n",
       " 'component',\n",
       " 'components',\n",
       " 'compos',\n",
       " 'composit',\n",
       " 'composition',\n",
       " 'compositional',\n",
       " 'compositionality',\n",
       " 'compositions',\n",
       " 'compound',\n",
       " 'comprehend',\n",
       " 'comprehens',\n",
       " 'comprehension',\n",
       " 'compress',\n",
       " 'compression',\n",
       " 'compris',\n",
       " 'compromis',\n",
       " 'comput',\n",
       " 'computation',\n",
       " 'computer',\n",
       " 'computers',\n",
       " 'computing',\n",
       " 'concaten',\n",
       " 'concentr',\n",
       " 'concept',\n",
       " 'conceptnet',\n",
       " 'concepts',\n",
       " 'conceptu',\n",
       " 'concern',\n",
       " 'concerns',\n",
       " 'concis',\n",
       " 'conclud',\n",
       " 'conclus',\n",
       " 'conclusion',\n",
       " 'conclusions',\n",
       " 'concret',\n",
       " 'concretely',\n",
       " 'concurr',\n",
       " 'condens',\n",
       " 'condit',\n",
       " 'condition',\n",
       " 'conditions',\n",
       " 'conduct',\n",
       " 'conducted',\n",
       " 'confer',\n",
       " 'confid',\n",
       " 'confidence',\n",
       " 'configur',\n",
       " 'configuration',\n",
       " 'configurations',\n",
       " 'confirm',\n",
       " 'conflat',\n",
       " 'conflict',\n",
       " 'conform',\n",
       " 'confound',\n",
       " 'confront',\n",
       " 'confus',\n",
       " 'conjectur',\n",
       " 'conjunct',\n",
       " 'conll',\n",
       " 'connect',\n",
       " 'connectionist',\n",
       " 'connections',\n",
       " 'connot',\n",
       " 'consecut',\n",
       " 'consensu',\n",
       " 'consequ',\n",
       " 'consequence',\n",
       " 'consequently',\n",
       " 'conserv',\n",
       " 'consid',\n",
       " 'consider',\n",
       " 'consideration',\n",
       " 'considered',\n",
       " 'consist',\n",
       " 'consistency',\n",
       " 'consistent',\n",
       " 'consolid',\n",
       " 'conson',\n",
       " 'conspiraci',\n",
       " 'constant',\n",
       " 'constantli',\n",
       " 'constitu',\n",
       " 'constituents',\n",
       " 'constitut',\n",
       " 'constrain',\n",
       " 'constraint',\n",
       " 'constraints',\n",
       " 'construct',\n",
       " 'constructed',\n",
       " 'construction',\n",
       " 'constructions',\n",
       " 'consult',\n",
       " 'consum',\n",
       " 'consuming',\n",
       " 'consumpt',\n",
       " ...]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be9b6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "384873e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "94ca5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(article):\n",
    "    article_index = new_df[new_df['article'] == article].index[0]\n",
    "    distances = similarity[article_index]\n",
    "    article_list = sorted(list(enumerate(distances)),reverse=True, key=lambda x:x[1])[1:11]\n",
    "    \n",
    "    for i in article_list:\n",
    "        print(new_df.iloc[i[0]].article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a398721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing for word sense disambiguation and\n",
      "  information extraction\n",
      "Relation Extraction : A Survey\n",
      "New Approaches for Natural Language Understanding based on the Idea that\n",
      "  Natural Language encodes both Information and its Processing Procedures\n",
      "Helping Crisis Responders Find the Informative Needle in the Tweet\n",
      "  Haystack\n",
      "Multimodal Attribute Extraction\n",
      "A natural language interface to a graph-based bibliographic information\n",
      "  retrieval system\n",
      "Fake News Detection by means of Uncertainty Weighted Causal Graphs\n",
      "Hierarchical RNN for Information Extraction from Lawsuit Documents\n",
      "Impact of News on the Commodity Market: Dataset and Results\n",
      "Pipelines for Procedural Information Extraction from Scientific\n",
      "  Literature: Towards Recipes using Machine Learning and Data Science\n"
     ]
    }
   ],
   "source": [
    "recommend('Natural Language Processing for Information Extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f56241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eda84d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('scholar.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70186a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(similarity, open('similarity.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b2e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
